{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "354904f1",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3f0db74e8a318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d47558",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import trimesh\n",
    "    TRIMESH_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"trimesh not available, using fallback for mesh operations.\")\n",
    "    TRIMESH_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "    SKLEARN_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Warning: sklearn not available, using custom metrics.\")\n",
    "    SKLEARN_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4040852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ba318cf477116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device and display GPU info\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory // 1024**3} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333457be",
   "metadata": {},
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf1795df5597187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET CONFIGURATION - CHANGE THIS TO SWITCH DATASETS\n",
    "DATASET_NAME = \"synthetic_rooms\"  # Options: \"synthetic_rooms\", \"shapenet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe819fc58ae6644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset configurations\n",
    "DATASET_CONFIGS = {\n",
    "    \"synthetic_rooms\": {\n",
    "        \"path\": \"./data/synthetic_rooms\",\n",
    "        \"point_cloud_size\": 2048,\n",
    "        \"sample_points\": 4096,\n",
    "        \"categories\": None,  # All room scenes\n",
    "        \"file_extension\": \".npz\",\n",
    "        \"normalize\": True\n",
    "    },\n",
    "    \"shapenet\": {\n",
    "        \"path\": \"./data/ShapeNet\",\n",
    "        \"point_cloud_size\": 2048,\n",
    "        \"sample_points\": 4096,\n",
    "        \"categories\": [\"03001627\", \"02958343\", \"04256520\"],  # chair, car, sofa\n",
    "        \"file_extension\": \".npz\",\n",
    "        \"normalize\": True\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81efbd83660a2239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current dataset config\n",
    "CURRENT_DATASET = DATASET_CONFIGS[DATASET_NAME]\n",
    "\n",
    "# Data parameters (dynamically set based on dataset)\n",
    "BATCH_SIZE = 4\n",
    "INPUT_DIM = 3\n",
    "OUTPUT_DIM = 1\n",
    "POINT_CLOUD_SIZE = CURRENT_DATASET[\"point_cloud_size\"]\n",
    "SAMPLE_POINTS = CURRENT_DATASET[\"sample_points\"]\n",
    "\n",
    "# Model parameters\n",
    "ENCODER_C_DIM = 16 # TODO: development phase : Reduced to 16 for development phase from 32\n",
    "DECODER_HIDDEN_DIM = 64 # TODO: development phase : Reduced to 64 for development phase from 128\n",
    "PLANE_RESOLUTION = 32 # TODO: development phase : Reduced to 32 for development phase from 64\n",
    "NUM_PLANES = 3  # XY, XZ, YZ planes\n",
    "\n",
    "# Training parameters\n",
    "LEARNING_RATE = 1e-3 # TODO: development phase : Reduced to 1e-3 for development phase from 1e-4\n",
    "NUM_EPOCHS = 20 # TODO: development phase : Reduced to 20 for development phase from 100\n",
    "SAVE_INTERVAL = 5 # TODO: development phase : Reduced to 5 for development phase from 10\n",
    "EVAL_INTERVAL = 2 # TODO: development phase : Reduced to 2 for development phase from 5\n",
    "\n",
    "# Paths (dynamically set based on dataset)\n",
    "DATA_PATH = CURRENT_DATASET[\"path\"]\n",
    "MODEL_SAVE_PATH = f\"./models/{DATASET_NAME}\"\n",
    "RESULTS_PATH = f\"./results/{DATASET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac97ef4ce421c848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if they don't exist\n",
    "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
    "os.makedirs(RESULTS_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e537e75d",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b073e42b0f7dc9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    \"\"\"Set random seed for reproducibility\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"Count the number of trainable parameters in a model\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45277e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_point_cloud(pc):\n",
    "    \"\"\"Normalize point cloud to unit sphere\"\"\"\n",
    "    centroid = np.mean(pc, axis=0)\n",
    "    pc = pc - centroid\n",
    "    max_dist = np.max(np.sqrt(np.sum(pc**2, axis=1)))\n",
    "    pc = pc / max_dist\n",
    "    return pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d10d1e0a85abde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, loss, path):\n",
    "    \"\"\"Save model checkpoint\"\"\"\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }, path)\n",
    "    print(f\"Checkpoint saved at {path}\")\n",
    "\n",
    "def load_checkpoint(model, optimizer, path):\n",
    "    \"\"\"Load model checkpoint\"\"\"\n",
    "    checkpoint = torch.load(path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    return checkpoint['epoch'], checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c8c3119af0148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset utilities\n",
    "def get_dataset_info():\n",
    "    \"\"\"Print current dataset configuration\"\"\"\n",
    "    print(f\"Current dataset: {DATASET_NAME}\")\n",
    "    print(f\"Dataset path: {DATA_PATH}\")\n",
    "    print(f\"Point cloud size: {POINT_CLOUD_SIZE}\")\n",
    "    print(f\"Sample points: {SAMPLE_POINTS}\")\n",
    "    if CURRENT_DATASET[\"categories\"]:\n",
    "        print(f\"Categories: {CURRENT_DATASET['categories']}\")\n",
    "\n",
    "def validate_dataset_path():\n",
    "    \"\"\"Validate that the dataset path exists\"\"\"\n",
    "    if not os.path.exists(DATA_PATH):\n",
    "        print(f\"Warning: Dataset path {DATA_PATH} does not exist!\")\n",
    "        print(\"Creating dummy data for development...\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def sample_points_on_mesh(vertices, faces, num_points=2048):\n",
    "    \"\"\"Sample points from mesh surface\"\"\"\n",
    "    if TRIMESH_AVAILABLE:\n",
    "        mesh = trimesh.Trimesh(vertices=vertices, faces=faces)\n",
    "        points, _ = trimesh.sample.sample_surface(mesh, num_points)\n",
    "        return points\n",
    "    else:\n",
    "        # Fallback: random sampling from vertices\n",
    "        indices = np.random.choice(len(vertices), num_points, replace=True)\n",
    "        return vertices[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cb79c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom metrics fallback if sklearn is not available\n",
    "def custom_accuracy_score(y_true, y_pred):\n",
    "    \"\"\"Custom accuracy score implementation\"\"\"\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "def custom_precision_score(y_true, y_pred):\n",
    "    \"\"\"Custom precision calculation\"\"\"\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    return tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "\n",
    "def custom_recall_score(y_true, y_pred):\n",
    "    \"\"\"Custom recall calculation\"\"\"\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    return tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "\n",
    "# Use sklearn if available, otherwise use custom implementations\n",
    "if SKLEARN_AVAILABLE:\n",
    "    accuracy_func = accuracy_score\n",
    "    precision_func = precision_score\n",
    "    recall_func = recall_score\n",
    "else:\n",
    "    accuracy_func = custom_accuracy_score\n",
    "    precision_func = custom_precision_score\n",
    "    recall_func = custom_recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6043c2782b251c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lightweight optimization utilities\n",
    "def apply_depthwise_separable_conv(in_channels, out_channels, kernel_size=3):\n",
    "    \"\"\"Create depthwise separable convolution layers\"\"\"\n",
    "    return nn.Sequential(\n",
    "        # Depthwise convolution\n",
    "        nn.Conv2d(in_channels, in_channels, kernel_size,\n",
    "                 padding=kernel_size//2, groups=in_channels, bias=False),\n",
    "        nn.BatchNorm2d(in_channels),\n",
    "        nn.ReLU(inplace=True),\n",
    "        # Pointwise convolution\n",
    "        nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "def prune_model(model, pruning_ratio=0.2):\n",
    "    \"\"\"Simple magnitude-based pruning\"\"\"\n",
    "    import torch.nn.utils.prune as prune\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "            prune.l1_unstructured(module, name='weight', amount=pruning_ratio)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc42d63d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11eeb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"Lightweight Convolutional Occupancy Networks for Virtual Scene Generation\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "set_seed(42)\n",
    "print(\"✓ Random seed set\")\n",
    "get_dataset_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8a22cf",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25d9cacb85d7399",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataset(Dataset):\n",
    "    \"\"\"Base dataset class with common functionality\"\"\"\n",
    "\n",
    "    def __init__(self, data_path, split='train', num_sample_points=SAMPLE_POINTS, dataset_type=DATASET_NAME):\n",
    "        self.data_path = data_path\n",
    "        self.split = split\n",
    "        self.num_sample_points = num_sample_points\n",
    "        self.dataset_type = dataset_type\n",
    "        self.config = CURRENT_DATASET\n",
    "\n",
    "        # Validate dataset exists\n",
    "        self.has_real_data = validate_dataset_path()\n",
    "\n",
    "        # Load data file paths\n",
    "        self.data_files = self._load_data_files()\n",
    "\n",
    "    def _load_data_files(self):\n",
    "        \"\"\"Load list of data files based on dataset type\"\"\"\n",
    "        if self.dataset_type == \"shapenet\":\n",
    "            return self._load_shapenet_files()\n",
    "        elif self.dataset_type == \"synthetic_rooms\":\n",
    "            return self._load_synthetic_rooms_files()\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown dataset type: {self.dataset_type}\")\n",
    "\n",
    "    def _load_shapenet_files(self):\n",
    "        \"\"\"Load ShapeNet file list\"\"\"\n",
    "        files = []\n",
    "        if self.has_real_data:\n",
    "            # Load from actual ShapeNet structure\n",
    "            for category in self.config[\"categories\"]:\n",
    "                category_path = os.path.join(self.data_path, category)\n",
    "                if os.path.exists(category_path):\n",
    "                    split_file = os.path.join(category_path, f\"{self.split}.lst\")\n",
    "                    if os.path.exists(split_file):\n",
    "                        with open(split_file, 'r') as f:\n",
    "                            category_files = [f\"{category}/{line.strip()}\" for line in f.readlines()]\n",
    "                            files.extend(category_files)\n",
    "\n",
    "        # Fallback to dummy data if no real data\n",
    "        if not files:\n",
    "            files = [f\"dummy_shapenet_{i}\" for i in range(200 if self.split == 'train' else 50)]\n",
    "\n",
    "        return files\n",
    "\n",
    "    def _load_synthetic_rooms_files(self):\n",
    "        \"\"\"Load Synthetic Rooms file list\"\"\"\n",
    "        files = []\n",
    "        if self.has_real_data:\n",
    "            split_file = os.path.join(self.data_path, f\"{self.split}.lst\")\n",
    "            if os.path.exists(split_file):\n",
    "                with open(split_file, 'r') as f:\n",
    "                    files = [line.strip() for line in f.readlines()]\n",
    "\n",
    "        # Fallback to dummy data if no real data\n",
    "        if not files:\n",
    "            files = [f\"dummy_rooms_{i}\" for i in range(100 if self.split == 'train' else 20)]\n",
    "\n",
    "        return files\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Get a single data sample\"\"\"\n",
    "        file_id = self.data_files[idx]\n",
    "\n",
    "        if self.has_real_data:\n",
    "            try:\n",
    "                # Try to load real data\n",
    "                return self._load_real_data(file_id)\n",
    "            except:\n",
    "                print(f\"Failed to load {file_id}, using synthetic data\")\n",
    "\n",
    "        # Generate synthetic data for development\n",
    "        return self._generate_synthetic_data(file_id)\n",
    "\n",
    "    def _load_real_data(self, file_id):\n",
    "        \"\"\"Load real dataset file\"\"\"\n",
    "        if self.dataset_type == \"shapenet\":\n",
    "            return self._load_shapenet_sample(file_id)\n",
    "        elif self.dataset_type == \"synthetic_rooms\":\n",
    "            return self._load_synthetic_rooms_sample(file_id)\n",
    "\n",
    "    def _load_shapenet_sample(self, file_id):\n",
    "        \"\"\"Load ShapeNet sample\"\"\"\n",
    "        file_path = os.path.join(self.data_path, file_id + self.config[\"file_extension\"])\n",
    "        data = np.load(file_path)\n",
    "\n",
    "        point_cloud = data['points'][:self.config[\"point_cloud_size\"]]\n",
    "        sample_points = data['points_iou'][:self.num_sample_points]\n",
    "        occupancy_values = data['occ'][:self.num_sample_points]\n",
    "\n",
    "        if self.config[\"normalize\"]:\n",
    "            point_cloud = normalize_point_cloud(point_cloud)\n",
    "            sample_points = normalize_point_cloud(sample_points)\n",
    "\n",
    "        return {\n",
    "            'point_cloud': torch.FloatTensor(point_cloud),\n",
    "            'sample_points': torch.FloatTensor(sample_points),\n",
    "            'occupancy': torch.FloatTensor(occupancy_values)\n",
    "        }\n",
    "\n",
    "    def _load_synthetic_rooms_sample(self, file_id):\n",
    "        \"\"\"Load Synthetic Rooms sample\"\"\"\n",
    "        file_path = os.path.join(self.data_path, file_id + self.config[\"file_extension\"])\n",
    "        data = np.load(file_path)\n",
    "\n",
    "        point_cloud = data['inputs'][:self.config[\"point_cloud_size\"]]\n",
    "        sample_points = data['points'][:self.num_sample_points]\n",
    "        occupancy_values = data['occupancies'][:self.num_sample_points]\n",
    "\n",
    "        if self.config[\"normalize\"]:\n",
    "            point_cloud = normalize_point_cloud(point_cloud)\n",
    "            sample_points = normalize_point_cloud(sample_points)\n",
    "\n",
    "        return {\n",
    "            'point_cloud': torch.FloatTensor(point_cloud),\n",
    "            'sample_points': torch.FloatTensor(sample_points),\n",
    "            'occupancy': torch.FloatTensor(occupancy_values)\n",
    "        }\n",
    "\n",
    "    def _generate_synthetic_data(self, file_id):\n",
    "        \"\"\"Generate synthetic data for development/testing\"\"\"\n",
    "        if self.dataset_type == \"shapenet\":\n",
    "            return self._generate_shapenet_synthetic()\n",
    "        else:  # synthetic_rooms\n",
    "            return self._generate_rooms_synthetic()\n",
    "\n",
    "    def _generate_shapenet_synthetic(self):\n",
    "        \"\"\"Generate synthetic ShapeNet-like data (simple shapes)\"\"\"\n",
    "        # Generate points on sphere surface for chair-like object\n",
    "        points = []\n",
    "        for _ in range(POINT_CLOUD_SIZE):\n",
    "            # Random point on unit sphere with some noise\n",
    "            theta = np.random.uniform(0, 2*np.pi)\n",
    "            phi = np.random.uniform(0, np.pi)\n",
    "            r = np.random.uniform(0.8, 1.2)\n",
    "\n",
    "            x = r * np.sin(phi) * np.cos(theta)\n",
    "            y = r * np.sin(phi) * np.sin(theta)\n",
    "            z = r * np.cos(phi)\n",
    "\n",
    "            points.append([x, y, z])\n",
    "\n",
    "        point_cloud = np.array(points)\n",
    "        sample_points = np.random.uniform(-1.5, 1.5, (self.num_sample_points, 3))\n",
    "\n",
    "        # Sphere occupancy: inside if distance < 1\n",
    "        distances = np.linalg.norm(sample_points, axis=1)\n",
    "        occupancy_values = (distances <= 1.0).astype(np.float32)\n",
    "\n",
    "        return {\n",
    "            'point_cloud': torch.FloatTensor(point_cloud),\n",
    "            'sample_points': torch.FloatTensor(sample_points),\n",
    "            'occupancy': torch.FloatTensor(occupancy_values)\n",
    "        }\n",
    "\n",
    "    def _generate_rooms_synthetic(self):\n",
    "        \"\"\"Generate synthetic room-like data (box structures)\"\"\"\n",
    "        # Generate points on cube faces for room-like structure\n",
    "        points = []\n",
    "        for _ in range(POINT_CLOUD_SIZE):\n",
    "            # Random point on one of 6 faces of a cube\n",
    "            face = np.random.randint(6)\n",
    "            if face == 0:  # +X face\n",
    "                point = [1.0, np.random.uniform(-1, 1), np.random.uniform(-1, 1)]\n",
    "            elif face == 1:  # -X face\n",
    "                point = [-1.0, np.random.uniform(-1, 1), np.random.uniform(-1, 1)]\n",
    "            elif face == 2:  # +Y face\n",
    "                point = [np.random.uniform(-1, 1), 1.0, np.random.uniform(-1, 1)]\n",
    "            elif face == 3:  # -Y face\n",
    "                point = [np.random.uniform(-1, 1), -1.0, np.random.uniform(-1, 1)]\n",
    "            elif face == 4:  # +Z face\n",
    "                point = [np.random.uniform(-1, 1), np.random.uniform(-1, 1), 1.0]\n",
    "            else:  # -Z face\n",
    "                point = [np.random.uniform(-1, 1), np.random.uniform(-1, 1), -1.0]\n",
    "\n",
    "            points.append(point)\n",
    "\n",
    "        point_cloud = np.array(points)\n",
    "        sample_points = np.random.uniform(-1.5, 1.5, (self.num_sample_points, 3))\n",
    "\n",
    "        # Cube occupancy: inside if all coordinates are in [-1, 1]\n",
    "        inside = np.all(np.abs(sample_points) <= 1.0, axis=1)\n",
    "        occupancy_values = inside.astype(np.float32)\n",
    "\n",
    "        return {\n",
    "            'point_cloud': torch.FloatTensor(point_cloud),\n",
    "            'sample_points': torch.FloatTensor(sample_points),\n",
    "            'occupancy': torch.FloatTensor(occupancy_values)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af049a48eb6e350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loaders(batch_size=BATCH_SIZE):\n",
    "    \"\"\"Create train and validation data loaders for current dataset\"\"\"\n",
    "    print(f\"Creating data loaders for {DATASET_NAME} dataset...\")\n",
    "    get_dataset_info()\n",
    "\n",
    "    train_dataset = BaseDataset(DATA_PATH, 'train')\n",
    "    val_dataset = BaseDataset(DATA_PATH, 'val')\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                             shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size,\n",
    "                           shuffle=False, num_workers=2)\n",
    "\n",
    "    print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "    print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da17142b",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1046dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n2. DATA LOADING\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "train_loader, val_loader = create_data_loaders()\n",
    "print(\"✓ Data loaders created\")\n",
    "\n",
    "# Show sample shapes\n",
    "sample_batch = next(iter(train_loader))\n",
    "for key, value in sample_batch.items():\n",
    "    print(f\"  {key}: {value.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e2e8ef",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf44755baa4d76fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightweightPointNet(nn.Module):\n",
    "    \"\"\"Lightweight PointNet for point cloud encoding\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim=3, output_dim=ENCODER_C_DIM):\n",
    "        super().__init__()\n",
    "\n",
    "        # Use depthwise separable convolutions for efficiency\n",
    "        self.conv1 = nn.Conv1d(input_dim, 32, 1)\n",
    "        self.conv2 = nn.Conv1d(32, 64, 1)\n",
    "        self.conv3 = nn.Conv1d(64, output_dim, 1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.bn3 = nn.BatchNorm1d(output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, num_points, 3)\n",
    "        x = x.transpose(2, 1)  # (batch_size, 3, num_points)\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "\n",
    "        # Global max pooling\n",
    "        x = torch.max(x, 2)[0]  # (batch_size, output_dim)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8163ce70e532d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightweightPlaneEncoder(nn.Module):\n",
    "    \"\"\"Lightweight encoder that projects features onto planes\"\"\"\n",
    "\n",
    "    def __init__(self, c_dim=ENCODER_C_DIM, plane_resolution=PLANE_RESOLUTION):\n",
    "        super().__init__()\n",
    "\n",
    "        self.c_dim = c_dim\n",
    "        self.plane_resolution = plane_resolution\n",
    "\n",
    "        # Point feature extractor\n",
    "        self.point_net = LightweightPointNet(3, c_dim)\n",
    "\n",
    "        # Lightweight plane feature networks using depthwise separable convolutions\n",
    "        self.xy_plane_net = self._make_plane_network()\n",
    "        self.xz_plane_net = self._make_plane_network()\n",
    "        self.yz_plane_net = self._make_plane_network()\n",
    "\n",
    "    def _make_plane_network(self):\n",
    "        \"\"\"Create lightweight plane feature network\"\"\"\n",
    "        return nn.Sequential(\n",
    "            apply_depthwise_separable_conv(self.c_dim, self.c_dim//2),\n",
    "            apply_depthwise_separable_conv(self.c_dim//2, self.c_dim//4),\n",
    "            nn.Conv2d(self.c_dim//4, self.c_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, point_cloud):\n",
    "        batch_size = point_cloud.shape[0]\n",
    "\n",
    "        # Extract point features\n",
    "        point_features = self.point_net(point_cloud)  # (B, c_dim)\n",
    "\n",
    "        # Project points onto planes and create feature maps\n",
    "        xy_features = self._project_to_plane(point_cloud, point_features, 'xy')\n",
    "        xz_features = self._project_to_plane(point_cloud, point_features, 'xz')\n",
    "        yz_features = self._project_to_plane(point_cloud, point_features, 'yz')\n",
    "\n",
    "        # Process plane features\n",
    "        xy_plane_features = self.xy_plane_net(xy_features)\n",
    "        xz_plane_features = self.xz_plane_net(xz_features)\n",
    "        yz_plane_features = self.yz_plane_net(yz_features)\n",
    "\n",
    "        return {\n",
    "            'xy': xy_plane_features,\n",
    "            'xz': xz_plane_features,\n",
    "            'yz': yz_plane_features\n",
    "        }\n",
    "\n",
    "    def _project_to_plane(self, points, features, plane_type):\n",
    "        \"\"\"Project points and features onto specified plane\"\"\"\n",
    "        batch_size = points.shape[0]\n",
    "\n",
    "        # Initialize feature map\n",
    "        feature_map = torch.zeros(batch_size, self.c_dim,\n",
    "                                 self.plane_resolution, self.plane_resolution,\n",
    "                                 device=points.device)\n",
    "\n",
    "        # Project points to 2D plane coordinates\n",
    "        if plane_type == 'xy':\n",
    "            coords_2d = points[:, :, [0, 1]]  # X, Y coordinates\n",
    "        elif plane_type == 'xz':\n",
    "            coords_2d = points[:, :, [0, 2]]  # X, Z coordinates\n",
    "        else:  # yz\n",
    "            coords_2d = points[:, :, [1, 2]]  # Y, Z coordinates\n",
    "\n",
    "        # Convert to pixel coordinates\n",
    "        coords_2d = (coords_2d + 1) / 2 * (self.plane_resolution - 1)\n",
    "        coords_2d = coords_2d.long().clamp(0, self.plane_resolution - 1)\n",
    "\n",
    "        # Scatter features to feature map (simplified version)\n",
    "        for b in range(batch_size):\n",
    "            for i, (x, y) in enumerate(coords_2d[b]):\n",
    "                feature_map[b, :, y, x] += features[b]\n",
    "\n",
    "        return feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e86e2833691093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightweightLocalDecoder(nn.Module):\n",
    "    \"\"\"Lightweight local decoder for occupancy prediction\"\"\"\n",
    "\n",
    "    def __init__(self, c_dim=ENCODER_C_DIM, hidden_dim=DECODER_HIDDEN_DIM):\n",
    "        super().__init__()\n",
    "\n",
    "        self.c_dim = c_dim\n",
    "\n",
    "        # Lightweight MLP with fewer parameters\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(3 + 3 * c_dim, hidden_dim//2),  # 3D point + 3 plane features\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_dim//2, hidden_dim//4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_dim//4, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, points, plane_features):\n",
    "        batch_size, num_points, _ = points.shape\n",
    "\n",
    "        # Sample features from each plane for the query points\n",
    "        xy_features = self._sample_plane_features(points, plane_features['xy'], 'xy')\n",
    "        xz_features = self._sample_plane_features(points, plane_features['xz'], 'xz')\n",
    "        yz_features = self._sample_plane_features(points, plane_features['yz'], 'yz')\n",
    "\n",
    "        # Concatenate point coordinates with plane features\n",
    "        features = torch.cat([\n",
    "            points.view(batch_size * num_points, 3),\n",
    "            xy_features.view(batch_size * num_points, -1),\n",
    "            xz_features.view(batch_size * num_points, -1),\n",
    "            yz_features.view(batch_size * num_points, -1)\n",
    "        ], dim=1)\n",
    "\n",
    "        # Predict occupancy\n",
    "        occupancy_logits = self.fc(features)\n",
    "\n",
    "        return occupancy_logits.view(batch_size, num_points)\n",
    "\n",
    "    def _sample_plane_features(self, points, plane_features, plane_type):\n",
    "        \"\"\"Sample features from plane feature map at query points\"\"\"\n",
    "        batch_size, num_points, _ = points.shape\n",
    "        _, c_dim, h, w = plane_features.shape\n",
    "\n",
    "        # Project points to plane coordinates\n",
    "        if plane_type == 'xy':\n",
    "            coords_2d = points[:, :, [0, 1]]\n",
    "        elif plane_type == 'xz':\n",
    "            coords_2d = points[:, :, [0, 2]]\n",
    "        else:  # yz\n",
    "            coords_2d = points[:, :, [1, 2]]\n",
    "\n",
    "        # Normalize coordinates to [-1, 1] for grid_sample\n",
    "        coords_2d = coords_2d.unsqueeze(2)  # (B, N, 1, 2)\n",
    "\n",
    "        # Sample features using bilinear interpolation\n",
    "        sampled_features = F.grid_sample(\n",
    "            plane_features, coords_2d,\n",
    "            mode='bilinear', padding_mode='border', align_corners=True\n",
    "        )  # (B, C, N, 1)\n",
    "\n",
    "        return sampled_features.squeeze(-1).transpose(1, 2)  # (B, N, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b1075f0366cb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightweightConvONet(nn.Module):\n",
    "    \"\"\"Main Lightweight Convolutional Occupancy Network\"\"\"\n",
    "\n",
    "    def __init__(self, c_dim=ENCODER_C_DIM, decoder_hidden_dim=DECODER_HIDDEN_DIM):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = LightweightPlaneEncoder(c_dim)\n",
    "        self.decoder = LightweightLocalDecoder(c_dim, decoder_hidden_dim)\n",
    "\n",
    "    def forward(self, point_cloud, sample_points):\n",
    "        # Encode point cloud to plane features\n",
    "        plane_features = self.encoder(point_cloud)\n",
    "\n",
    "        # Decode occupancy for sample points\n",
    "        occupancy_logits = self.decoder(sample_points, plane_features)\n",
    "\n",
    "        return occupancy_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03edace0",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419f6742b318cd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \"\"\"Training class for Lightweight ConvONet\"\"\"\n",
    "\n",
    "    def __init__(self, model, optimizer, device):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        # Training metrics\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.val_accuracies = []\n",
    "\n",
    "    def train_epoch(self, train_loader):\n",
    "        \"\"\"Train for one epoch\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        total_samples = 0\n",
    "        correct_predictions = 0\n",
    "\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            point_cloud = batch['point_cloud'].to(self.device)\n",
    "            sample_points = batch['sample_points'].to(self.device)\n",
    "            occupancy = batch['occupancy'].to(self.device)\n",
    "\n",
    "            # Forward pass\n",
    "            self.optimizer.zero_grad()\n",
    "            occupancy_logits = self.model(point_cloud, sample_points)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = self.criterion(occupancy_logits, occupancy)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # Statistics\n",
    "            total_loss += loss.item() * point_cloud.size(0)\n",
    "            total_samples += point_cloud.size(0)\n",
    "\n",
    "            # Accuracy\n",
    "            predictions = torch.sigmoid(occupancy_logits) > 0.5\n",
    "            correct_predictions += (predictions == occupancy).sum().item()\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f'Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
    "\n",
    "        avg_loss = total_loss / total_samples\n",
    "        accuracy = correct_predictions / (total_samples * SAMPLE_POINTS)\n",
    "\n",
    "        return avg_loss, accuracy\n",
    "\n",
    "    def validate(self, val_loader):\n",
    "        \"\"\"Validate the model\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        total_samples = 0\n",
    "        correct_predictions = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                point_cloud = batch['point_cloud'].to(self.device)\n",
    "                sample_points = batch['sample_points'].to(self.device)\n",
    "                occupancy = batch['occupancy'].to(self.device)\n",
    "\n",
    "                # Forward pass\n",
    "                occupancy_logits = self.model(point_cloud, sample_points)\n",
    "                loss = self.criterion(occupancy_logits, occupancy)\n",
    "\n",
    "                # Statistics\n",
    "                total_loss += loss.item() * point_cloud.size(0)\n",
    "                total_samples += point_cloud.size(0)\n",
    "\n",
    "                # Accuracy\n",
    "                predictions = torch.sigmoid(occupancy_logits) > 0.5\n",
    "                correct_predictions += (predictions == occupancy).sum().item()\n",
    "\n",
    "        avg_loss = total_loss / total_samples\n",
    "        accuracy = correct_predictions / (total_samples * SAMPLE_POINTS)\n",
    "\n",
    "        return avg_loss, accuracy\n",
    "\n",
    "    def train(self, train_loader, val_loader, num_epochs):\n",
    "        \"\"\"Full training loop\"\"\"\n",
    "        print(\"Starting training...\")\n",
    "        print(f\"Model parameters: {count_parameters(self.model):,}\")\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Train\n",
    "            train_loss, train_acc = self.train_epoch(train_loader)\n",
    "            self.train_losses.append(train_loss)\n",
    "            self.train_accuracies.append(train_acc)\n",
    "\n",
    "            # Validate\n",
    "            if epoch % EVAL_INTERVAL == 0:\n",
    "                val_loss, val_acc = self.validate(val_loader)\n",
    "                self.val_losses.append(val_loss)\n",
    "                self.val_accuracies.append(val_acc)\n",
    "\n",
    "                epoch_time = time.time() - start_time\n",
    "\n",
    "                print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "                print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "                print(f'  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "                print(f'  Time: {epoch_time:.2f}s')\n",
    "\n",
    "                # Save best model\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    save_checkpoint(\n",
    "                        self.model, self.optimizer, epoch, val_loss,\n",
    "                        os.path.join(MODEL_SAVE_PATH, 'best_model.pth')\n",
    "                    )\n",
    "\n",
    "                # Save regular checkpoint\n",
    "                if epoch % SAVE_INTERVAL == 0:\n",
    "                    save_checkpoint(\n",
    "                        self.model, self.optimizer, epoch, val_loss,\n",
    "                        os.path.join(MODEL_SAVE_PATH, f'checkpoint_epoch_{epoch}.pth')\n",
    "                    )\n",
    "\n",
    "        print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144ab2a4ad9207f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_and_optimizer():\n",
    "    \"\"\"Create model and optimizer\"\"\"\n",
    "    model = LightweightConvONet().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "\n",
    "    print(f\"Model created with {count_parameters(model):,} parameters\")\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cf54c0",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5922f137",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n3. MODEL CREATION\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "model, optimizer = create_model_and_optimizer()\n",
    "print(\"✓ Model created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2767e62a",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffd0057",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n4. TRAINING\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "trainer = Trainer(model, optimizer, device)\n",
    "trainer.train(train_loader, val_loader, NUM_EPOCHS)\n",
    "print(\"✓ Training completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcb33db",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b3a73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n5. TRAINING CURVES\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "plot_training_curves(trainer)\n",
    "print(\"✓ Plots generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe2e8f5",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea18b7330adb4966",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    \"\"\"Evaluation class for Lightweight ConvONet\"\"\"\n",
    "\n",
    "    def __init__(self, model, device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "    def evaluate_reconstruction_metrics(self, test_loader):\n",
    "        \"\"\"Evaluate reconstruction quality metrics\"\"\"\n",
    "        self.model.eval()\n",
    "\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        inference_times = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                point_cloud = batch['point_cloud'].to(self.device)\n",
    "                sample_points = batch['sample_points'].to(self.device)\n",
    "                occupancy = batch['occupancy'].to(self.device)\n",
    "\n",
    "                # Measure inference time\n",
    "                start_time = time.time()\n",
    "                occupancy_logits = self.model(point_cloud, sample_points)\n",
    "                inference_time = time.time() - start_time\n",
    "                inference_times.append(inference_time)\n",
    "\n",
    "                # Convert to predictions\n",
    "                predictions = torch.sigmoid(occupancy_logits) > 0.5\n",
    "\n",
    "                all_predictions.append(predictions.cpu().numpy())\n",
    "                all_targets.append(occupancy.cpu().numpy())\n",
    "\n",
    "        # Flatten arrays\n",
    "        all_predictions = np.concatenate(all_predictions).flatten()\n",
    "        all_targets = np.concatenate(all_targets).flatten()\n",
    "\n",
    "        # Compute metrics with error handling\n",
    "        if SKLEARN_AVAILABLE:\n",
    "            accuracy = accuracy_score(all_targets, all_predictions)\n",
    "            precision = precision_score(all_targets, all_predictions, zero_division=0)\n",
    "            recall = recall_score(all_targets, all_predictions, zero_division=0)\n",
    "        else:\n",
    "            accuracy = accuracy_func(all_targets, all_predictions)\n",
    "            precision = precision_func(all_targets, all_predictions)\n",
    "            recall = recall_func(all_targets, all_predictions)\n",
    "            \n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        avg_inference_time = np.mean(inference_times)\n",
    "\n",
    "        metrics = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1_score,\n",
    "            'avg_inference_time': avg_inference_time,\n",
    "            'throughput': len(test_loader.dataset) / sum(inference_times)\n",
    "        }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def benchmark_inference_speed(self, test_loader, num_runs=10):\n",
    "        \"\"\"Benchmark inference speed\"\"\"\n",
    "        self.model.eval()\n",
    "\n",
    "        # Warm up\n",
    "        for _ in range(5):\n",
    "            batch = next(iter(test_loader))\n",
    "            point_cloud = batch['point_cloud'].to(self.device)\n",
    "            sample_points = batch['sample_points'].to(self.device)\n",
    "            with torch.no_grad():\n",
    "                _ = self.model(point_cloud, sample_points)\n",
    "\n",
    "        # Benchmark\n",
    "        times = []\n",
    "        for _ in range(num_runs):\n",
    "            batch = next(iter(test_loader))\n",
    "            point_cloud = batch['point_cloud'].to(self.device)\n",
    "            sample_points = batch['sample_points'].to(self.device)\n",
    "\n",
    "            start_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                _ = self.model(point_cloud, sample_points)\n",
    "            torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "            end_time = time.time()\n",
    "\n",
    "            times.append(end_time - start_time)\n",
    "\n",
    "        return {\n",
    "            'mean_time': np.mean(times),\n",
    "            'std_time': np.std(times),\n",
    "            'min_time': np.min(times),\n",
    "            'max_time': np.max(times)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537ea9a36fa33b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves(trainer):\n",
    "    \"\"\"Plot training and validation curves\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Loss curves\n",
    "    axes[0].plot(trainer.train_losses, label='Train Loss')\n",
    "    if trainer.val_losses:\n",
    "        val_epochs = [i * EVAL_INTERVAL for i in range(len(trainer.val_losses))]\n",
    "        axes[0].plot(val_epochs, trainer.val_losses, label='Validation Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Accuracy curves\n",
    "    axes[1].plot(trainer.train_accuracies, label='Train Accuracy')\n",
    "    if trainer.val_accuracies:\n",
    "        val_epochs = [i * EVAL_INTERVAL for i in range(len(trainer.val_accuracies))]\n",
    "        axes[1].plot(val_epochs, trainer.val_accuracies, label='Validation Accuracy')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_title('Training and Validation Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULTS_PATH, 'training_curves.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c45c8b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770e14a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n6. EVALUATION\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "evaluator = Evaluator(model, device)\n",
    "val_metrics = evaluator.evaluate_reconstruction_metrics(val_loader)\n",
    "\n",
    "for metric, value in val_metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91f7504",
   "metadata": {},
   "source": [
    "## Speed Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2803e956",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n7. SPEED BENCHMARK\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "speed_metrics = evaluator.benchmark_inference_speed(val_loader)\n",
    "for metric, value in speed_metrics.items():\n",
    "    print(f\"  {metric}: {value:.6f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048e7385",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ca9888",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n8. SUMMARY\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Dataset: {DATASET_NAME}\")\n",
    "print(f\"Parameters: {count_parameters(model):,}\")\n",
    "print(f\"Accuracy: {val_metrics['accuracy']:.4f}\")\n",
    "print(f\"Inference: {val_metrics['avg_inference_time']:.6f}s\")\n",
    "print(\"✅ Complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
